{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "esCFMU8BXdEb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6hQEeDqORd1"
      },
      "outputs": [],
      "source": [
        "class Logistic_Regression:\n",
        "    '''\n",
        "    Docstring for Logistic_Regression\n",
        "    >> model = Logistic_Regression()\n",
        "    >> model.fit(X_train, y_train)\n",
        "    >> model.preict(X_test)\n",
        "    '''\n",
        "\n",
        "    def __init__(self, threshold = 0.5, learning_rate = 0.01, iteartion = 100):\n",
        "\n",
        "        self.threshold = threshold\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iteartion = iteartion\n",
        "        self.W = None\n",
        "        self.b = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        '''\n",
        "        rows - m\n",
        "        cols/features - d\n",
        "\n",
        "        X_train : m x d\n",
        "        y_train : m x 1\n",
        "\n",
        "        '''\n",
        "        m, d = X_train.shape\n",
        "\n",
        "        # W : d x 1\n",
        "        self.W = np.zeros((d,1))\n",
        "        self.b = 0\n",
        "\n",
        "        for i in range(self.iteartion):\n",
        "\n",
        "            z = np.dot(X_train, self.W) + self.b\n",
        "\n",
        "            #to prevent overflowing floating point value\n",
        "            z = np.clip(z, -708, 708)\n",
        "\n",
        "            y_hat = 1/(1+np.exp(-z)) # use raw probability\n",
        "\n",
        "            dW = (-1) * np.dot(X_train.T, (y_train - y_hat))/m\n",
        "            db = (-1) * np.mean((y_train - y_hat))\n",
        "\n",
        "            self.W -= self.learning_rate * dW\n",
        "            self.b -= self.learning_rate * db\n",
        "\n",
        "\n",
        "    def predict(self, X_test):\n",
        "\n",
        "        z = np.dot(X_test, self.W) + self.b\n",
        "\n",
        "        #to prevent overflowing floating point value\n",
        "        z = np.clip(z, -708, 708)\n",
        "\n",
        "        y_hat = 1/(1+np.exp(-z))\n",
        "        y_hat = np.where(y_hat > self.threshold, 1, 0) # thresholding in only prediction\n",
        "\n",
        "        return y_hat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def score(y_true, y_pred):\n",
        "    return np.sum(y_true == y_pred)/y_pred.shape[0]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
